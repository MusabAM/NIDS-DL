{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Autoencoder for UNSW-NB15\n",
    "\n",
    "This notebook trains a **Semi-Supervised Autoencoder** for intrusion detection on the **UNSW-NB15** dataset.\n",
    "\n",
    "**Key Strategy:**\n",
    "- **Hybrid Approach**: The model is trained primarily on **Normal** data to learn reconstruction, but also includes a small fraction of **Attack** data with a contrastive loss.\n",
    "- **Objective**: Minimize reconstruction error for normal traffic while maximizing separation from known attacks.\n",
    "- **Advantage**: Better decision boundary than purely unsupervised methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path(\"../../\").resolve()))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 50,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"hidden_dims\": [256, 128, 64],\n",
    "    \"latent_dim\": 32,\n",
    "    \"dropout\": 0.3,\n",
    "    \"patience\": 15,\n",
    "    \"recon_weight\": 0.3,\n",
    "    \"class_weight\": 0.7,\n",
    "}\n",
    "\n",
    "CATEGORICAL_COLS = ['proto', 'service', 'state']\n",
    "DROP_COLS = ['id', 'attack_cat']\n",
    "LABEL_COL = 'label'\n",
    "DATA_DIR = Path(\"../../data/raw/unsw-nb15\")\n",
    "\n",
    "def load_unsw_nb15(filepath, scaler=None, label_encoders=None, fit=True):\n",
    "    if not filepath.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    df = df.drop(columns=[c for c in DROP_COLS if c in df.columns], errors='ignore')\n",
    "    y = df[LABEL_COL].values\n",
    "    X = df.drop(columns=[LABEL_COL])\n",
    "    \n",
    "    if fit:\n",
    "        label_encoders = {}\n",
    "        for col in CATEGORICAL_COLS:\n",
    "            if col in X.columns:\n",
    "                le = LabelEncoder()\n",
    "                X[col] = X[col].fillna('unknown').astype(str)\n",
    "                X[col] = le.fit_transform(X[col])\n",
    "                label_encoders[col] = le\n",
    "    else:\n",
    "        for col in CATEGORICAL_COLS:\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].fillna('unknown').astype(str)\n",
    "                X[col] = X[col].apply(lambda x: x if x in label_encoders[col].classes_ else 'unknown')\n",
    "                if 'unknown' not in label_encoders[col].classes_:\n",
    "                    label_encoders[col].classes_ = np.append(label_encoders[col].classes_, 'unknown')\n",
    "                X[col] = label_encoders[col].transform(X[col])\n",
    "    \n",
    "    X = X.fillna(0).values.astype(np.float32)\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    if fit:\n",
    "        scaler = MinMaxScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X = scaler.transform(X)\n",
    "        X = np.clip(X, 0, 1)\n",
    "        \n",
    "    return X, y, scaler, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (45540, 42), Val: (5059, 42), Test: (175341, 42)\n",
      "Attack samples in training: 13,599\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load ALL training data\n",
    "    X_train_full, y_train_full, scaler, label_encoders = load_unsw_nb15(\n",
    "        DATA_DIR / \"UNSW_NB15_training-set.csv\", fit=True\n",
    "    )\n",
    "    \n",
    "    X_test, y_test, _, _ = load_unsw_nb15(\n",
    "        DATA_DIR / \"UNSW_NB15_testing-set.csv\", \n",
    "        scaler=scaler, label_encoders=label_encoders, fit=False\n",
    "    )\n",
    "    \n",
    "    # Prepare Semi-Supervised Data\n",
    "    # Use ALL Normal data + 30% of Attack data for training\n",
    "    normal_mask = (y_train_full == 0)\n",
    "    attack_mask = (y_train_full == 1)\n",
    "    \n",
    "    X_normal = X_train_full[normal_mask]\n",
    "    y_normal = y_train_full[normal_mask]\n",
    "    X_attack = X_train_full[attack_mask]\n",
    "    y_attack = y_train_full[attack_mask]\n",
    "    \n",
    "    n_attack_train = int(0.3 * len(X_attack))\n",
    "    indices = np.random.permutation(len(X_attack))\n",
    "    \n",
    "    X_attack_train = X_attack[indices[:n_attack_train]]\n",
    "    y_attack_train = y_attack[indices[:n_attack_train]]\n",
    "    \n",
    "    X_train = np.vstack([X_normal, X_attack_train])\n",
    "    y_train = np.concatenate([y_normal, y_attack_train])\n",
    "    \n",
    "    # Shuffle\n",
    "    shuffle_idx = np.random.permutation(len(X_train))\n",
    "    X_train = X_train[shuffle_idx]\n",
    "    y_train = y_train[shuffle_idx]\n",
    "    \n",
    "    # Validation Split of Mixed Data\n",
    "    val_size = int(0.1 * len(X_train))\n",
    "    X_val = X_train[:val_size]\n",
    "    y_val = y_train[:val_size]\n",
    "    X_train = X_train[val_size:]\n",
    "    y_train = y_train[val_size:]\n",
    "    \n",
    "    print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "    print(f\"Attack samples in training: {n_attack_train:,}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Dataset not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Definition\n",
    "This autoencoder has a classification head attached to the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on cuda\n"
     ]
    }
   ],
   "source": [
    "class SemiSupervisedAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[256, 128, 64], latent_dim=32, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.input_bn = nn.BatchNorm1d(input_dim)\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(in_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            in_dim = h_dim\n",
    "        layers.append(nn.Linear(in_dim, latent_dim))\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        \n",
    "        # Decoder\n",
    "        layers = []\n",
    "        in_dim = latent_dim\n",
    "        for h_dim in reversed(hidden_dims):\n",
    "            layers.extend([\n",
    "                nn.Linear(in_dim, h_dim),\n",
    "                nn.BatchNorm1d(h_dim),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Dropout(dropout * 0.5)\n",
    "            ])\n",
    "            in_dim = h_dim\n",
    "        layers.extend([\n",
    "            nn.Linear(in_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        ])\n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "        \n",
    "        # Classifier Head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_norm = self.input_bn(x)\n",
    "        z = self.encoder(x_norm)\n",
    "        x_recon = self.decoder(z)\n",
    "        logits = self.classifier(z)\n",
    "        return x_recon, z, logits\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if 'X_train' in globals():\n",
    "    model = SemiSupervisedAutoencoder(\n",
    "        input_dim=X_train.shape[1],\n",
    "        hidden_dims=CONFIG[\"hidden_dims\"],\n",
    "        latent_dim=CONFIG[\"latent_dim\"],\n",
    "        dropout=CONFIG[\"dropout\"]\n",
    "    ).to(device)\n",
    "    print(f\"Model on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musab\\Projects\\NIDS-DL\\venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loss Functions\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = torch.FloatTensor(len(y_train) / (2 * class_counts)).to(device)\n",
    "\n",
    "criterion_recon = nn.MSELoss()\n",
    "criterion_class = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train)), \n",
    "    batch_size=CONFIG[\"batch_size\"], shuffle=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(torch.FloatTensor(X_val), torch.LongTensor(y_val)), \n",
    "    batch_size=CONFIG[\"batch_size\"], shuffle=False\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test)), \n",
    "    batch_size=CONFIG[\"batch_size\"], shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x_recon, z, logits = model(X_batch)\n",
    "        \n",
    "        loss_recon = criterion_recon(x_recon, X_batch)\n",
    "        loss_class = criterion_class(logits, y_batch)\n",
    "        loss = CONFIG[\"recon_weight\"] * loss_recon + CONFIG[\"class_weight\"] * loss_class\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, pred = logits.max(1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += pred.eq(y_batch).sum().item()\n",
    "        \n",
    "    return total_loss/len(loader), correct/total\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            x_recon, z, logits = model(X_batch)\n",
    "            \n",
    "            loss_recon = criterion_recon(x_recon, X_batch)\n",
    "            loss_class = criterion_class(logits, y_batch)\n",
    "            loss = CONFIG[\"recon_weight\"] * loss_recon + CONFIG[\"class_weight\"] * loss_class\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, pred = logits.max(1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += pred.eq(y_batch).sum().item()\n",
    "            \n",
    "    return total_loss/len(loader), correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Acc: 0.9375 | Val Acc: 0.9583\n",
      "Epoch 10 | Train Acc: 0.9453 | Val Acc: 0.9488\n",
      "Epoch 15 | Train Acc: 0.9522 | Val Acc: 0.9652\n",
      "Epoch 20 | Train Acc: 0.9534 | Val Acc: 0.9526\n",
      "Epoch 25 | Train Acc: 0.9555 | Val Acc: 0.9658\n",
      "Epoch 30 | Train Acc: 0.9575 | Val Acc: 0.9674\n",
      "Epoch 35 | Train Acc: 0.9564 | Val Acc: 0.9684\n",
      "Epoch 40 | Train Acc: 0.9559 | Val Acc: 0.9666\n",
      "Epoch 45 | Train Acc: 0.9563 | Val Acc: 0.9624\n",
      "Epoch 50 | Train Acc: 0.9560 | Val Acc: 0.9658\n"
     ]
    }
   ],
   "source": [
    "if 'X_train' in globals():\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    for epoch in range(CONFIG[\"epochs\"]):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer)\n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "        \n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"../../results/models/autoencoder_unsw.pt\")\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musab\\AppData\\Local\\Temp\\ipykernel_52552\\1386865408.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"../../results/models/autoencoder_unsw.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.74      0.98      0.84     56000\n",
      "      Attack       0.99      0.84      0.91    119341\n",
      "\n",
      "    accuracy                           0.88    175341\n",
      "   macro avg       0.86      0.91      0.87    175341\n",
      "weighted avg       0.91      0.88      0.88    175341\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4155"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'X_train' in globals():\n",
    "    model.load_state_dict(torch.load(\"../../results/models/autoencoder_unsw.pt\"))\n",
    "    test_loss, test_acc = evaluate(model, test_loader)\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            _, _, logits = model(X_batch)\n",
    "            _, pred = logits.max(1)\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(y_batch.numpy())\n",
    "    \n",
    "    print(classification_report(all_labels, all_preds, target_names=['Normal', 'Attack']))\n",
    "    sns.heatmap(confusion_matrix(all_labels, all_preds), annot=True, fmt='d', cmap='Blues')\n",
    "    plt.show()\n",
    "\n",
    "#Cleanup\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
