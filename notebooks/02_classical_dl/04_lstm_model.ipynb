{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LSTM Model for Network Intrusion Detection\n",
                "\n",
                "This notebook implements and evaluates a Bidirectional LSTM model for binary classification on the NSL-KDD dataset.\n",
                "\n",
                "**Model Overview:**\n",
                "- Bidirectional LSTM (3 layers, 256 hidden units)\n",
                "- Binary classification: Normal vs Attack\n",
                "- Test Accuracy: **80.78%**\n",
                "\n",
                "**Author:** LSTM Implementation for NIDS-DL Project"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '../..')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.metrics import (\n",
                "    classification_report, confusion_matrix, \n",
                "    accuracy_score, roc_curve, auc, precision_recall_curve\n",
                ")\n",
                "\n",
                "# Configure plotting\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "plt.rcParams['font.size'] = 12\n",
                "\n",
                "# Check GPU availability\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "print(\"Setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load NSL-KDD Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Column names for NSL-KDD\n",
                "COLUMNS = [\n",
                "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
                "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n",
                "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
                "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
                "    'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate',\n",
                "    'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
                "    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
                "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
                "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
                "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label', 'difficulty_level'\n",
                "]\n",
                "\n",
                "# Binary classification mapping\n",
                "ATTACK_MAPPING = {\n",
                "    'normal': 0,\n",
                "    'back': 1, 'land': 1, 'neptune': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,\n",
                "    'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1,\n",
                "    'ipsweep': 1, 'nmap': 1, 'portsweep': 1, 'satan': 1, 'mscan': 1, 'saint': 1,\n",
                "    'ftp_write': 1, 'guess_passwd': 1, 'imap': 1, 'multihop': 1, 'phf': 1,\n",
                "    'spy': 1, 'warezclient': 1, 'warezmaster': 1, 'sendmail': 1, 'named': 1,\n",
                "    'snmpgetattack': 1, 'snmpguess': 1, 'xlock': 1, 'xsnoop': 1, 'worm': 1,\n",
                "    'buffer_overflow': 1, 'loadmodule': 1, 'perl': 1, 'rootkit': 1,\n",
                "    'httptunnel': 1, 'ps': 1, 'sqlattack': 1, 'xterm': 1,\n",
                "}\n",
                "\n",
                "# Load data\n",
                "DATA_PATH = Path('../../data/raw/nsl-kdd/')\n",
                "train_df = pd.read_csv(DATA_PATH / 'train.txt', header=None, names=COLUMNS)\n",
                "test_df = pd.read_csv(DATA_PATH / 'test.txt', header=None, names=COLUMNS)\n",
                "\n",
                "print(f\"Training samples: {len(train_df):,}\")\n",
                "print(f\"Test samples: {len(test_df):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess_data(train_df, test_df):\n",
                "    \"\"\"Preprocess NSL-KDD data for LSTM model.\"\"\"\n",
                "    # Remove difficulty level\n",
                "    train_df = train_df.drop('difficulty_level', axis=1)\n",
                "    test_df = test_df.drop('difficulty_level', axis=1)\n",
                "    \n",
                "    # Map labels to binary\n",
                "    train_df['label'] = train_df['label'].map(lambda x: ATTACK_MAPPING.get(x, 1))\n",
                "    test_df['label'] = test_df['label'].map(lambda x: ATTACK_MAPPING.get(x, 1))\n",
                "    \n",
                "    # Separate features and labels\n",
                "    X_train = train_df.drop('label', axis=1)\n",
                "    y_train = train_df['label'].values\n",
                "    X_test = test_df.drop('label', axis=1)\n",
                "    y_test = test_df['label'].values\n",
                "    \n",
                "    # Encode categorical features\n",
                "    cat_cols = ['protocol_type', 'service', 'flag']\n",
                "    label_encoders = {}\n",
                "    \n",
                "    for col in cat_cols:\n",
                "        le = LabelEncoder()\n",
                "        X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
                "        # Handle unseen labels in test set\n",
                "        X_test[col] = X_test[col].apply(lambda x: x if x in le.classes_ else 'unknown')\n",
                "        if 'unknown' not in le.classes_:\n",
                "            le.classes_ = np.append(le.classes_, 'unknown')\n",
                "        X_test[col] = le.transform(X_test[col].astype(str))\n",
                "        label_encoders[col] = le\n",
                "    \n",
                "    # Normalize features\n",
                "    scaler = StandardScaler()\n",
                "    X_train = scaler.fit_transform(X_train.values.astype(np.float32))\n",
                "    X_test = scaler.transform(X_test.values.astype(np.float32))\n",
                "    \n",
                "    return X_train, y_train, X_test, y_test, scaler\n",
                "\n",
                "X_train, y_train, X_test, y_test, scaler = preprocess_data(train_df.copy(), test_df.copy())\n",
                "\n",
                "# Create validation split\n",
                "val_size = int(0.1 * len(X_train))\n",
                "indices = np.random.permutation(len(X_train))\n",
                "X_val, y_val = X_train[indices[:val_size]], y_train[indices[:val_size]]\n",
                "X_train, y_train = X_train[indices[val_size:]], y_train[indices[val_size:]]\n",
                "\n",
                "print(f\"\\nDataset shapes:\")\n",
                "print(f\"  Training:   {X_train.shape}\")\n",
                "print(f\"  Validation: {X_val.shape}\")\n",
                "print(f\"  Test:       {X_test.shape}\")\n",
                "print(f\"\\nClass distribution (Train): Normal={sum(y_train==0):,}, Attack={sum(y_train==1):,}\")\n",
                "print(f\"Class distribution (Test):  Normal={sum(y_test==0):,}, Attack={sum(y_test==1):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. LSTM Model Architecture"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ImprovedLSTMClassifier(nn.Module):\n",
                "    \"\"\"\n",
                "    Bidirectional LSTM for Network Intrusion Detection.\n",
                "    \n",
                "    Architecture:\n",
                "    - Input BatchNorm + Linear embedding\n",
                "    - 3-layer Bidirectional LSTM (256 hidden units)\n",
                "    - Classification head with BatchNorm and Dropout\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, input_dim, num_classes=2, hidden_dim=256, \n",
                "                 num_layers=3, dropout=0.4, bidirectional=True):\n",
                "        super().__init__()\n",
                "        \n",
                "        self.hidden_dim = hidden_dim\n",
                "        self.num_layers = num_layers\n",
                "        self.num_directions = 2 if bidirectional else 1\n",
                "        \n",
                "        # Feature embedding\n",
                "        self.input_bn = nn.BatchNorm1d(input_dim)\n",
                "        self.input_fc = nn.Linear(input_dim, hidden_dim)\n",
                "        \n",
                "        # LSTM\n",
                "        self.lstm = nn.LSTM(\n",
                "            input_size=hidden_dim,\n",
                "            hidden_size=hidden_dim,\n",
                "            num_layers=num_layers,\n",
                "            batch_first=True,\n",
                "            dropout=dropout if num_layers > 1 else 0,\n",
                "            bidirectional=bidirectional,\n",
                "        )\n",
                "        \n",
                "        # Classification head\n",
                "        self.classifier = nn.Sequential(\n",
                "            nn.BatchNorm1d(hidden_dim * self.num_directions),\n",
                "            nn.Dropout(dropout),\n",
                "            nn.Linear(hidden_dim * self.num_directions, 128),\n",
                "            nn.ReLU(),\n",
                "            nn.BatchNorm1d(128),\n",
                "            nn.Dropout(dropout * 0.5),\n",
                "            nn.Linear(128, 64),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(64, num_classes),\n",
                "        )\n",
                "        \n",
                "    def forward(self, x):\n",
                "        x = self.input_bn(x)\n",
                "        x = torch.relu(self.input_fc(x))\n",
                "        x = x.unsqueeze(1)  # (batch, 1, features)\n",
                "        lstm_out, _ = self.lstm(x)\n",
                "        x = lstm_out[:, -1, :]\n",
                "        return self.classifier(x)\n",
                "\n",
                "# Create model\n",
                "model = ImprovedLSTMClassifier(\n",
                "    input_dim=X_train.shape[1],\n",
                "    num_classes=2,\n",
                "    hidden_dim=256,\n",
                "    num_layers=3,\n",
                "    dropout=0.4,\n",
                "    bidirectional=True\n",
                ").to(device)\n",
                "\n",
                "# Model summary\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f\"Model: ImprovedLSTMClassifier\")\n",
                "print(f\"Total parameters: {total_params:,}\")\n",
                "print(f\"Trainable parameters: {trainable:,}\")\n",
                "print(f\"\\nArchitecture:\")\n",
                "print(model)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Training Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hyperparameters\n",
                "CONFIG = {\n",
                "    'batch_size': 512,\n",
                "    'epochs': 100,\n",
                "    'learning_rate': 0.0005,\n",
                "    'weight_decay': 1e-4,\n",
                "    'patience': 20,\n",
                "}\n",
                "\n",
                "print(\"Training Configuration:\")\n",
                "for key, value in CONFIG.items():\n",
                "    print(f\"  {key}: {value}\")\n",
                "\n",
                "# Create DataLoaders\n",
                "train_dataset = torch.utils.data.TensorDataset(\n",
                "    torch.FloatTensor(X_train), torch.LongTensor(y_train)\n",
                ")\n",
                "val_dataset = torch.utils.data.TensorDataset(\n",
                "    torch.FloatTensor(X_val), torch.LongTensor(y_val)\n",
                ")\n",
                "test_dataset = torch.utils.data.TensorDataset(\n",
                "    torch.FloatTensor(X_test), torch.LongTensor(y_test)\n",
                ")\n",
                "\n",
                "train_loader = torch.utils.data.DataLoader(\n",
                "    train_dataset, batch_size=CONFIG['batch_size'], shuffle=True\n",
                ")\n",
                "val_loader = torch.utils.data.DataLoader(\n",
                "    val_dataset, batch_size=CONFIG['batch_size'], shuffle=False\n",
                ")\n",
                "test_loader = torch.utils.data.DataLoader(\n",
                "    test_dataset, batch_size=CONFIG['batch_size'], shuffle=False\n",
                ")\n",
                "\n",
                "# Class weights for imbalanced data\n",
                "class_counts = np.bincount(y_train)\n",
                "class_weights = torch.FloatTensor(len(y_train) / (2 * class_counts)).to(device)\n",
                "print(f\"\\nClass weights: {class_weights.cpu().numpy()}\")\n",
                "\n",
                "# Loss, optimizer, scheduler\n",
                "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
                "optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
                "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_epoch(model, loader, criterion, optimizer, device):\n",
                "    model.train()\n",
                "    total_loss, correct, total = 0, 0, 0\n",
                "    \n",
                "    for X_batch, y_batch in loader:\n",
                "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(X_batch)\n",
                "        loss = criterion(outputs, y_batch)\n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
                "        optimizer.step()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "        _, predicted = outputs.max(1)\n",
                "        total += y_batch.size(0)\n",
                "        correct += predicted.eq(y_batch).sum().item()\n",
                "    \n",
                "    return total_loss / len(loader), correct / total\n",
                "\n",
                "def evaluate(model, loader, criterion, device):\n",
                "    model.eval()\n",
                "    total_loss, correct, total = 0, 0, 0\n",
                "    all_preds, all_labels, all_probs = [], [], []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for X_batch, y_batch in loader:\n",
                "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
                "            outputs = model(X_batch)\n",
                "            loss = criterion(outputs, y_batch)\n",
                "            \n",
                "            total_loss += loss.item()\n",
                "            probs = torch.softmax(outputs, dim=1)\n",
                "            _, predicted = outputs.max(1)\n",
                "            total += y_batch.size(0)\n",
                "            correct += predicted.eq(y_batch).sum().item()\n",
                "            \n",
                "            all_preds.extend(predicted.cpu().numpy())\n",
                "            all_labels.extend(y_batch.cpu().numpy())\n",
                "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
                "    \n",
                "    return total_loss / len(loader), correct / total, all_preds, all_labels, all_probs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training\n",
                "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
                "best_val_acc = 0\n",
                "patience_counter = 0\n",
                "\n",
                "print(f\"Training for {CONFIG['epochs']} epochs...\\n\")\n",
                "\n",
                "for epoch in range(CONFIG['epochs']):\n",
                "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
                "    val_loss, val_acc, _, _, _ = evaluate(model, val_loader, criterion, device)\n",
                "    \n",
                "    history['train_loss'].append(train_loss)\n",
                "    history['train_acc'].append(train_acc)\n",
                "    history['val_loss'].append(val_loss)\n",
                "    history['val_acc'].append(val_acc)\n",
                "    \n",
                "    scheduler.step(val_acc)\n",
                "    \n",
                "    if val_acc > best_val_acc:\n",
                "        best_val_acc = val_acc\n",
                "        patience_counter = 0\n",
                "        torch.save(model.state_dict(), '../../results/models/lstm_notebook_best.pt')\n",
                "        marker = \" â˜… Best!\"\n",
                "    else:\n",
                "        patience_counter += 1\n",
                "        marker = \"\"\n",
                "    \n",
                "    if (epoch + 1) % 10 == 0 or marker:\n",
                "        print(f\"Epoch {epoch+1:3d}/{CONFIG['epochs']} | \"\n",
                "              f\"Train: {train_acc*100:.2f}% | Val: {val_acc*100:.2f}%{marker}\")\n",
                "    \n",
                "    if patience_counter >= CONFIG['patience']:\n",
                "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
                "        break\n",
                "\n",
                "print(f\"\\nBest validation accuracy: {best_val_acc*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Training History Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Loss plot\n",
                "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
                "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('Loss')\n",
                "axes[0].set_title('Training and Validation Loss')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True)\n",
                "\n",
                "# Accuracy plot\n",
                "axes[1].plot([x*100 for x in history['train_acc']], label='Train Acc', linewidth=2)\n",
                "axes[1].plot([x*100 for x in history['val_acc']], label='Val Acc', linewidth=2)\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].set_ylabel('Accuracy (%)')\n",
                "axes[1].set_title('Training and Validation Accuracy')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../../results/figures/lstm_training_curves.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Test Set Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "model.load_state_dict(torch.load('../../results/models/lstm_notebook_best.pt'))\n",
                "\n",
                "# Evaluate on test set\n",
                "test_loss, test_acc, preds, labels, probs = evaluate(model, test_loader, criterion, device)\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\" LSTM Model - Test Set Results\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"\\nTest Accuracy: {test_acc*100:.2f}%\")\n",
                "print(f\"Test Loss: {test_loss:.4f}\")\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(labels, preds, target_names=['Normal', 'Attack']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute confusion matrix\n",
                "cm = confusion_matrix(labels, preds)\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Raw counts\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'], ax=axes[0])\n",
                "axes[0].set_xlabel('Predicted')\n",
                "axes[0].set_ylabel('Actual')\n",
                "axes[0].set_title('Confusion Matrix (Counts)')\n",
                "\n",
                "# Normalized\n",
                "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
                "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues',\n",
                "            xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'], ax=axes[1])\n",
                "axes[1].set_xlabel('Predicted')\n",
                "axes[1].set_ylabel('Actual')\n",
                "axes[1].set_title('Confusion Matrix (Normalized)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../../results/figures/lstm_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nTrue Positives (Attack detected):  {cm[1,1]:,}\")\n",
                "print(f\"True Negatives (Normal detected):  {cm[0,0]:,}\")\n",
                "print(f\"False Positives (Normalâ†’Attack):   {cm[0,1]:,}\")\n",
                "print(f\"False Negatives (Attackâ†’Normal):   {cm[1,0]:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. ROC Curve and AUC"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute ROC curve\n",
                "fpr, tpr, thresholds = roc_curve(labels, probs)\n",
                "roc_auc = auc(fpr, tpr)\n",
                "\n",
                "# Compute Precision-Recall curve\n",
                "precision, recall, _ = precision_recall_curve(labels, probs)\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# ROC Curve\n",
                "axes[0].plot(fpr, tpr, 'b-', linewidth=2, label=f'LSTM (AUC = {roc_auc:.4f})')\n",
                "axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
                "axes[0].set_xlabel('False Positive Rate')\n",
                "axes[0].set_ylabel('True Positive Rate')\n",
                "axes[0].set_title('ROC Curve')\n",
                "axes[0].legend(loc='lower right')\n",
                "axes[0].grid(True)\n",
                "\n",
                "# Precision-Recall Curve\n",
                "axes[1].plot(recall, precision, 'g-', linewidth=2, label='LSTM')\n",
                "axes[1].set_xlabel('Recall')\n",
                "axes[1].set_ylabel('Precision')\n",
                "axes[1].set_title('Precision-Recall Curve')\n",
                "axes[1].legend(loc='lower left')\n",
                "axes[1].grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../../results/figures/lstm_roc_pr_curves.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"AUC-ROC Score: {roc_auc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Model Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\" LSTM MODEL SUMMARY - NIDS on NSL-KDD\")\n",
                "print(\"=\" * 60)\n",
                "print(\"\\nðŸ“Š Dataset:\")\n",
                "print(f\"   Training samples:   {len(X_train):,}\")\n",
                "print(f\"   Validation samples: {len(X_val):,}\")\n",
                "print(f\"   Test samples:       {len(X_test):,}\")\n",
                "print(f\"   Features:           {X_train.shape[1]}\")\n",
                "\n",
                "print(\"\\nðŸ§  Model Architecture:\")\n",
                "print(f\"   Type: Bidirectional LSTM\")\n",
                "print(f\"   Layers: 3\")\n",
                "print(f\"   Hidden units: 256\")\n",
                "print(f\"   Parameters: {total_params:,}\")\n",
                "print(f\"   Dropout: 0.4\")\n",
                "\n",
                "print(\"\\nâš™ï¸ Training Configuration:\")\n",
                "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
                "print(f\"   Learning rate: {CONFIG['learning_rate']}\")\n",
                "print(f\"   Optimizer: AdamW\")\n",
                "print(f\"   Scheduler: ReduceLROnPlateau\")\n",
                "\n",
                "print(\"\\nðŸŽ¯ Results:\")\n",
                "print(f\"   Test Accuracy:  {test_acc*100:.2f}%\")\n",
                "print(f\"   AUC-ROC:        {roc_auc:.4f}\")\n",
                "print(f\"   Best Val Acc:   {best_val_acc*100:.2f}%\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\" âœ… TARGET ACHIEVED: Accuracy > 78%\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save results summary\n",
                "results = {\n",
                "    'model': 'Bidirectional LSTM',\n",
                "    'dataset': 'NSL-KDD',\n",
                "    'test_accuracy': test_acc,\n",
                "    'auc_roc': roc_auc,\n",
                "    'best_val_accuracy': best_val_acc,\n",
                "    'total_params': total_params,\n",
                "    'epochs_trained': len(history['train_loss']),\n",
                "    'config': CONFIG,\n",
                "}\n",
                "\n",
                "import json\n",
                "with open('../../results/logs/lstm_notebook_results.json', 'w') as f:\n",
                "    json.dump(results, f, indent=2)\n",
                "\n",
                "print(\"Results saved to: results/logs/lstm_notebook_results.json\")\n",
                "print(\"Model saved to: results/models/lstm_notebook_best.pt\")\n",
                "print(\"Figures saved to: results/figures/\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}