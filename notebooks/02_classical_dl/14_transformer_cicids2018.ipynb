{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Transformer Classifier Training on CICIDS2018\n",
                "\n",
                "This notebook trains a **Transformer** for binary classification on the CICIDS2018 dataset.\n",
                "\n",
                "**Model:** TransformerClassifier (PyTorch)  \n",
                "**Dataset:** CICIDS2018  \n",
                "**Task:** Binary Classification (Benign vs Attack)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append(str(Path(\"../../\").resolve()))\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import glob\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader, TensorDataset\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "import matplotlib.pyplot as plt\n",
                "from src.models.classical.transformer import TransformerClassifier\n",
                "import time\n",
                "import gc\n",
                "\n",
                "# Check GPU availability\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load and Preprocess Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data (Reuse loading logic)\n",
                "DATA_PATH = '../../data/raw/cicids2018/'\n",
                "all_files = glob.glob(os.path.join(DATA_PATH, \"*.csv\"))\n",
                "li = []\n",
                "\n",
                "for filename in all_files:\n",
                "    if os.path.getsize(filename) > 1000 * 1024 * 1024:\n",
                "        continue\n",
                "    try:\n",
                "        df_temp = pd.read_csv(filename, low_memory=True)\n",
                "        df_temp.columns = df_temp.columns.str.strip()\n",
                "        \n",
                "        # Basic cleaning\n",
                "        drop_cols = ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Label']\n",
                "        label_col = df_temp['Label']\n",
                "        df_temp = df_temp.drop(columns=[c for c in drop_cols if c in df_temp.columns and c != 'Label'], errors='ignore')\n",
                "        \n",
                "        li.append(df_temp)\n",
                "    except: pass\n",
                "\n",
                "df = pd.concat(li, ignore_index=True)\n",
                "print(f\"Loaded {len(df):,} samples\")\n",
                "del li\n",
                "gc.collect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create Labels & Clean\n",
                "def create_binary_label(label):\n",
                "    return 0 if isinstance(label, str) and 'BENIGN' in label.upper() else 1\n",
                "\n",
                "df['binary_label'] = df['Label'].apply(create_binary_label)\n",
                "df.drop(columns=['Label'], inplace=True, errors='ignore')\n",
                "\n",
                "for col in df.columns:\n",
                "    if col != 'binary_label':\n",
                "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
                "\n",
                "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
                "df.dropna(inplace=True)\n",
                "\n",
                "# Sample (Transformer is memory intensive)\n",
                "SAMPLE_SIZE = 300000\n",
                "benign = df[df['binary_label'] == 0].sample(n=min(len(df[df['binary_label']==0]), SAMPLE_SIZE), random_state=42)\n",
                "attack = df[df['binary_label'] == 1].sample(n=min(len(df[df['binary_label']==1]), SAMPLE_SIZE), random_state=42)\n",
                "df = pd.concat([benign, attack], ignore_index=True)\n",
                "\n",
                "y = df['binary_label'].values\n",
                "X = df.drop(columns=['binary_label']).values.astype(np.float32)\n",
                "del df, benign, attack\n",
                "gc.collect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split & Scale\n",
                "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
                "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X_train = scaler.fit_transform(X_train)\n",
                "X_val = scaler.transform(X_val)\n",
                "X_test = scaler.transform(X_test)\n",
                "\n",
                "BATCH_SIZE = 256\n",
                "train_loader = DataLoader(TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train)), batch_size=BATCH_SIZE, shuffle=True)\n",
                "val_loader = DataLoader(TensorDataset(torch.FloatTensor(X_val), torch.LongTensor(y_val)), batch_size=BATCH_SIZE, shuffle=False)\n",
                "test_loader = DataLoader(TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test)), batch_size=BATCH_SIZE, shuffle=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Transformer Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = TransformerClassifier(\n",
                "    input_dim=X_train.shape[1],\n",
                "    num_classes=2,\n",
                "    embed_dim=64,\n",
                "    num_heads=4,\n",
                "    ff_dim=128,\n",
                "    num_blocks=3,\n",
                "    dense_units=[64],\n",
                "    dropout=0.3\n",
                ").to(device)\n",
                "\n",
                "print(model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.AdamW(model.parameters(), lr=0.0005)\n",
                "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)\n",
                "\n",
                "def train_epoch(model, loader, criterion, optimizer):\n",
                "    model.train()\n",
                "    total_loss, correct, total = 0, 0, 0\n",
                "    for X_batch, y_batch in loader:\n",
                "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(X_batch)\n",
                "        loss = criterion(outputs, y_batch)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item() * X_batch.size(0)\n",
                "        _, predicted = torch.max(outputs, 1)\n",
                "        total += y_batch.size(0)\n",
                "        correct += (predicted == y_batch).sum().item()\n",
                "    return total_loss / total, correct / total\n",
                "\n",
                "def validate(model, loader, criterion):\n",
                "    model.eval()\n",
                "    total_loss, correct, total = 0, 0, 0\n",
                "    with torch.no_grad():\n",
                "        for X_batch, y_batch in loader:\n",
                "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
                "            outputs = model(X_batch)\n",
                "            loss = criterion(outputs, y_batch)\n",
                "            total_loss += loss.item() * X_batch.size(0)\n",
                "            _, predicted = torch.max(outputs, 1)\n",
                "            total += y_batch.size(0)\n",
                "            correct += (predicted == y_batch).sum().item()\n",
                "    return total_loss / total, correct / total"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "EPOCHS = 30\n",
                "best_val_acc = 0\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
                "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
                "    scheduler.step(val_acc)\n",
                "    \n",
                "    print(f\"Epoch {epoch+1} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
                "    \n",
                "    if val_acc > best_val_acc:\n",
                "        best_val_acc = val_acc\n",
                "        torch.save(model.state_dict(), \"../../results/models/transformer_cicids2018_best.pt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluation\n",
                "model.load_state_dict(torch.load(\"../../results/models/transformer_cicids2018_best.pt\"))\n",
                "model.eval()\n",
                "\n",
                "all_preds, all_labels = [], []\n",
                "with torch.no_grad():\n",
                "    for X_batch, y_batch in test_loader:\n",
                "        X_batch = X_batch.to(device)\n",
                "        outputs = model(X_batch)\n",
                "        _, predicted = torch.max(outputs, 1)\n",
                "        all_preds.extend(predicted.cpu().numpy())\n",
                "        all_labels.extend(y_batch.numpy())\n",
                "\n",
                "print(classification_report(all_labels, all_preds, target_names=['Benign', 'Attack']))\n",
                "print(\"Confusion Matrix:\")\n",
                "print(confusion_matrix(all_labels, all_preds))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}