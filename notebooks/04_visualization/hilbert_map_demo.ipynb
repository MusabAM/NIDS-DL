{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hilbert Map GPU Visualization Demo\n",
    "\n",
    "This notebook demonstrates how to use Hilbert space-filling curves to:\n",
    "1. Test GPU computational performance\n",
    "2. Visualize model predictions and network traffic patterns\n",
    "3. Create 2D representations of high-dimensional data\n",
    "\n",
    "## What is a Hilbert Curve?\n",
    "\n",
    "A Hilbert curve is a continuous fractal space-filling curve that maps one-dimensional data to two-dimensional space while preserving locality. Points that are close together in 1D remain close in 2D.\n",
    "\n",
    "**Benefits for NIDS:**\n",
    "- Visualize temporal patterns in network traffic\n",
    "- Identify clusters of similar attacks\n",
    "- Test GPU performance with your models\n",
    "- Create intuitive 2D visualizations of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.visualization.hilbert_map import (\n",
    "    HilbertCurve, \n",
    "    benchmark_gpu_performance,\n",
    "    visualize_model_predictions\n",
    ")\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Imports successful!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Basic Hilbert Curves\n",
    "\n",
    "Let's start by generating Hilbert curves of different orders to understand the pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate curves of different orders\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "orders = [2, 3, 4, 5]\n",
    "\n",
    "for idx, order in enumerate(orders):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    hc = HilbertCurve(order=order, use_gpu=False)\n",
    "    x_coords, y_coords = hc.generate_curve()\n",
    "    \n",
    "    ax.plot(x_coords, y_coords, 'b-', linewidth=1, alpha=0.7)\n",
    "    ax.scatter(x_coords, y_coords, c=range(len(x_coords)), \n",
    "               cmap='viridis', s=30, alpha=0.6, zorder=5)\n",
    "    ax.set_title(f'Order {order} ({2**order}x{2**order} = {(2**order)**2} points)',\n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/hilbert_curves_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how the curve becomes more complex as order increases!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU Performance Benchmark\n",
    "\n",
    "Test your GPU's computational capabilities by comparing CPU vs GPU performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Benchmark GPU performance\n",
    "print(\"Running GPU/CPU performance comparison...\\n\")\n",
    "results = benchmark_gpu_performance(orders=[4, 5, 6, 7, 8])\n",
    "\n",
    "# Visualize results\n",
    "if any(results['gpu_times']):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot computation times\n",
    "    ax1.plot(results['orders'], results['cpu_times'], \n",
    "             'o-', label='CPU', linewidth=2, markersize=8)\n",
    "    if all(t is not None for t in results['gpu_times']):\n",
    "        ax1.plot(results['orders'], results['gpu_times'], \n",
    "                 's-', label='GPU', linewidth=2, markersize=8)\n",
    "    ax1.set_xlabel('Curve Order', fontsize=12)\n",
    "    ax1.set_ylabel('Time (seconds)', fontsize=12)\n",
    "    ax1.set_title('Computation Time Comparison', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_yscale('log')\n",
    "    \n",
    "    # Plot speedup\n",
    "    if all(s is not None for s in results['speedups']):\n",
    "        ax2.bar(results['orders'], results['speedups'], \n",
    "                color='green', alpha=0.7, edgecolor='black')\n",
    "        ax2.axhline(y=1, color='red', linestyle='--', \n",
    "                    linewidth=2, label='No speedup')\n",
    "        ax2.set_xlabel('Curve Order', fontsize=12)\n",
    "        ax2.set_ylabel('Speedup (CPU time / GPU time)', fontsize=12)\n",
    "        ax2.set_title('GPU Speedup Factor', fontsize=14, fontweight='bold')\n",
    "        ax2.legend(fontsize=11)\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, v in enumerate(results['speedups']):\n",
    "            if v is not None:\n",
    "                ax2.text(results['orders'][i], v + 0.1, f'{v:.2f}x',\n",
    "                        ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../../results/gpu_benchmark.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"GPU not available. Install cupy-cuda12x for GPU support.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Synthetic Data\n",
    "\n",
    "Let's create some synthetic patterns to understand how data maps to the Hilbert curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "hc = HilbertCurve(order=6, use_gpu=True)\n",
    "n_points = 2**6 * 2**6  # 4096 points\n",
    "\n",
    "# Create different patterns\n",
    "patterns = {\n",
    "    'Sine Wave': np.sin(np.linspace(0, 8*np.pi, n_points)),\n",
    "    'Step Function': np.concatenate([\n",
    "        np.zeros(n_points//4),\n",
    "        np.ones(n_points//4),\n",
    "        np.zeros(n_points//4),\n",
    "        np.ones(n_points//4)\n",
    "    ]),\n",
    "    'Random Noise': np.random.randn(n_points),\n",
    "    'Linear Gradient': np.linspace(0, 1, n_points)\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "for idx, (name, data) in enumerate(patterns.items()):\n",
    "    # 1D view\n",
    "    ax1 = axes[0, idx]\n",
    "    ax1.plot(data, linewidth=1)\n",
    "    ax1.set_title(f'{name} (1D)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Index')\n",
    "    ax1.set_ylabel('Value')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2D Hilbert mapping\n",
    "    ax2 = axes[1, idx]\n",
    "    grid = hc.map_data_to_curve(data)\n",
    "    im = ax2.imshow(grid, cmap='viridis', interpolation='nearest', origin='lower')\n",
    "    ax2.set_title(f'{name} (Hilbert)', fontsize=12, fontweight='bold')\n",
    "    plt.colorbar(im, ax=ax2, fraction=0.046)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/hilbert_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how patterns in 1D are preserved in 2D space!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Model Predictions (Synthetic)\n",
    "\n",
    "Create synthetic predictions to demonstrate how to visualize model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate synthetic predictions\n",
    "n_samples = 4096\n",
    "\n",
    "# Create patterns: normal traffic followed by attacks\n",
    "predictions = np.zeros(n_samples)\n",
    "predictions[1000:1500] = 1  # Attack cluster 1\n",
    "predictions[2500:3000] = 1  # Attack cluster 2\n",
    "predictions[3500:3800] = 1  # Attack cluster 3\n",
    "\n",
    "# Add some noise (false positives/negatives)\n",
    "noise_indices = np.random.choice(n_samples, size=100, replace=False)\n",
    "predictions[noise_indices] = 1 - predictions[noise_indices]\n",
    "\n",
    "# Create true labels (slightly different)\n",
    "labels = predictions.copy()\n",
    "error_indices = np.random.choice(n_samples, size=50, replace=False)\n",
    "labels[error_indices] = 1 - labels[error_indices]\n",
    "\n",
    "# Visualize\n",
    "visualize_model_predictions(\n",
    "    predictions=predictions,\n",
    "    labels=labels,\n",
    "    order=6,\n",
    "    use_gpu=True,\n",
    "    save_dir='../../results'\n",
    ")\n",
    "\n",
    "print(\"\"\"\\n✓ Generated visualizations:\n",
    "  - predictions_hilbert.png: Model predictions\n",
    "  - labels_hilbert.png: True labels\n",
    "  - errors_hilbert.png: Prediction errors (misclassifications)\\n\"\"\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Visualize Real Model Predictions\n",
    "\n",
    "Now let's use actual model predictions from your trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example: Load predictions from a saved model\n",
    "# Uncomment and modify the path to use your actual model\n",
    "\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load your trained model\n",
    "model_path = '../../results/models/cnn_nsl_kdd_best.h5'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Load test data\n",
    "X_test = pd.read_csv('../../data/processed/NSL_KDD/Test/X_test.csv')\n",
    "y_test = pd.read_csv('../../data/processed/NSL_KDD/Test/y_test.csv')['label'].values\n",
    "\n",
    "# Preprocess\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "# Make predictions\n",
    "predictions_prob = model.predict(X_test_scaled)\n",
    "predictions = (predictions_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Visualize on Hilbert curve\n",
    "visualize_model_predictions(\n",
    "    predictions=predictions[:8192],  # Use first 8192 samples (order 7)\n",
    "    labels=y_test[:8192],\n",
    "    order=7,\n",
    "    use_gpu=True,\n",
    "    save_dir='../../results/model_viz'\n",
    ")\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test[:8192], predictions[:8192], \n",
    "                          target_names=['Normal', 'Attack']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test[:8192], predictions[:8192]))\n",
    "\"\"\"\n",
    "\n",
    "print(\"\"\"\\nTo use real model predictions:\n",
    "1. Uncomment the code above\n",
    "2. Update the model_path to your trained model\n",
    "3. Update data paths to your test set\n",
    "4. Run the cell!\"\"\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interactive Exploration\n",
    "\n",
    "Create your own custom visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a custom Hilbert curve visualization\n",
    "order = 7  # Adjust this (2-8 recommended)\n",
    "use_gpu = True  # Set to False if no GPU\n",
    "\n",
    "hc = HilbertCurve(order=order, use_gpu=use_gpu)\n",
    "\n",
    "# Option 1: Visualize the curve itself\n",
    "# hc.visualize_curve(save_path=f'../../results/my_hilbert_order{order}.png')\n",
    "\n",
    "# Option 2: Visualize custom data\n",
    "n_points = (2**order) ** 2\n",
    "custom_data = np.random.rand(n_points)  # Replace with your data\n",
    "hc.visualize_data(\n",
    "    custom_data,\n",
    "    title=\"My Custom Data Visualization\",\n",
    "    cmap='plasma',  # Try: viridis, plasma, inferno, magma, RdYlGn\n",
    "    save_path=f'../../results/my_custom_viz_order{order}.png'\n",
    ")\n",
    "\n",
    "print(f\"✓ Created visualization with {n_points:,} points!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "✅ Generate Hilbert space-filling curves of different orders  \n",
    "✅ Benchmark GPU vs CPU performance  \n",
    "✅ Map 1D data to 2D Hilbert space  \n",
    "✅ Visualize synthetic and real model predictions  \n",
    "✅ Identify patterns and clusters in network traffic  \n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Test with your models**: Load predictions from your CNN, LSTM, or Transformer models\n",
    "2. **Experiment with orders**: Try different orders (7-8 for large datasets)\n",
    "3. **GPU testing**: Use this for GPU stress testing and performance benchmarking\n",
    "4. **Pattern analysis**: Look for temporal patterns in attack sequences\n",
    "\n",
    "### Tips:\n",
    "\n",
    "- **Order selection**: Use `order = ceil(log2(sqrt(n_samples)))` for optimal fit\n",
    "- **GPU acceleration**: Install `cupy-cuda12x` for CUDA 12.x or `cupy-cuda11x` for CUDA 11.x\n",
    "- **Memory**: Higher orders require more memory (order 10 = 1M points)\n",
    "- **Colormaps**: Use diverging colormaps (RdYlGn) for binary data, sequential (viridis) for continuous"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
